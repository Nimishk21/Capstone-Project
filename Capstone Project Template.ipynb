{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    ".getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import first,split\n",
    "from pyspark.sql.functions import upper, col\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType, IntegerType\n",
    "from pyspark.sql.functions import udf, date_format\n",
    "import datetime as dt\n",
    "from pyspark.sql.functions import col, countDistinct\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Government Organization wants to keep track on the non immigration trends so as to analyze trend in toursims accross various states and students coming in Unites states for studying.So they want to develop a data model that would help them to observe the cities that students and non immigrants visits or come to study.We will create a star schema of dimensions and fact tables from immigration and US cities demographics to analyze various trends\n",
    "\n",
    "#### Describe and Gather Data \n",
    "The data we are using is I94 Immigration data provided as SAS_data in workspace and US cities demographics under csv file in workspace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start ETL of US CITIES DEMOGRAPHICS DATA SET:\n",
    "This data looks pretty clean.The exploration steps involve:\n",
    "1.Looking at a single city. This reveals the grain of the table to be city/state/race. Removing the Race and Count columns gives you duplicate data\n",
    "2.Seeing that the total of Count for all the races adds up to more than Total Population, indicating people must have been allowed to select more than one race for themselves in the survey.\n",
    "3.Selecting distinct state codes to be sure that the number was near 50 (to account for 50 states, DC, PR, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City',\n",
       " 'State',\n",
       " 'Median Age',\n",
       " 'Male Population',\n",
       " 'Female Population',\n",
       " 'Total Population',\n",
       " 'Number of Veterans',\n",
       " 'Foreign-born',\n",
       " 'Average Household Size',\n",
       " 'State Code',\n",
       " 'Race',\n",
       " 'Count']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the demographic data here\n",
    "us_demo=spark.read.csv(\"./us-cities-demographics.csv\", sep=';', header=True)\n",
    "us_demo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+---------------+-----------------+----------------+------------+----------------------+\n",
      "|   City|     state|Median Age|male population|female population|total population|foreign-born|Average Household Size|\n",
      "+-------+----------+----------+---------------+-----------------+----------------+------------+----------------------+\n",
      "|Abilene|     Texas|      31.3|          65212|            60664|          125876|        8129|                  2.64|\n",
      "|Abilene|     Texas|      31.3|          65212|            60664|          125876|        8129|                  2.64|\n",
      "|Abilene|     Texas|      31.3|          65212|            60664|          125876|        8129|                  2.64|\n",
      "|Abilene|     Texas|      31.3|          65212|            60664|          125876|        8129|                  2.64|\n",
      "|Abilene|     Texas|      31.3|          65212|            60664|          125876|        8129|                  2.64|\n",
      "|  Akron|      Ohio|      38.1|          96886|           100667|          197553|       10024|                  2.24|\n",
      "|  Akron|      Ohio|      38.1|          96886|           100667|          197553|       10024|                  2.24|\n",
      "|  Akron|      Ohio|      38.1|          96886|           100667|          197553|       10024|                  2.24|\n",
      "|  Akron|      Ohio|      38.1|          96886|           100667|          197553|       10024|                  2.24|\n",
      "|  Akron|      Ohio|      38.1|          96886|           100667|          197553|       10024|                  2.24|\n",
      "|Alafaya|   Florida|      33.5|          39504|            45760|           85264|       15842|                  2.94|\n",
      "|Alafaya|   Florida|      33.5|          39504|            45760|           85264|       15842|                  2.94|\n",
      "|Alafaya|   Florida|      33.5|          39504|            45760|           85264|       15842|                  2.94|\n",
      "|Alafaya|   Florida|      33.5|          39504|            45760|           85264|       15842|                  2.94|\n",
      "|Alameda|California|      41.4|          37747|            40867|           78614|       18841|                  2.52|\n",
      "|Alameda|California|      41.4|          37747|            40867|           78614|       18841|                  2.52|\n",
      "|Alameda|California|      41.4|          37747|            40867|           78614|       18841|                  2.52|\n",
      "|Alameda|California|      41.4|          37747|            40867|           78614|       18841|                  2.52|\n",
      "|Alameda|California|      41.4|          37747|            40867|           78614|       18841|                  2.52|\n",
      "| Albany|  New York|      32.8|          47627|            50825|           98452|       11948|                  2.08|\n",
      "+-------+----------+----------+---------------+-----------------+----------------+------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check dataset for any data quality issues\n",
    "us_demo.select(\"City\",\"state\",\"Median Age\",\"male population\",\"female population\",\"total population\", \\\n",
    "                  \"foreign-born\",\"Average Household Size\").orderBy(\"city\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------------------+------+\n",
      "|   city|state code|                Race| count|\n",
      "+-------+----------+--------------------+------+\n",
      "|Abilene|        TX|American Indian a...|  1813|\n",
      "|Abilene|        TX|  Hispanic or Latino| 33222|\n",
      "|Abilene|        TX|               White| 95487|\n",
      "|Abilene|        TX|               Asian|  2929|\n",
      "|Abilene|        TX|Black or African-...| 14449|\n",
      "|  Akron|        OH|               White|129192|\n",
      "|  Akron|        OH|  Hispanic or Latino|  3684|\n",
      "|  Akron|        OH|Black or African-...| 66551|\n",
      "|  Akron|        OH|               Asian|  9033|\n",
      "|  Akron|        OH|American Indian a...|  1845|\n",
      "|Alafaya|        FL|  Hispanic or Latino| 34897|\n",
      "|Alafaya|        FL|               Asian| 10336|\n",
      "|Alafaya|        FL|               White| 63666|\n",
      "|Alafaya|        FL|Black or African-...|  6577|\n",
      "|Alameda|        CA|               White| 44232|\n",
      "|Alameda|        CA|American Indian a...|  1329|\n",
      "|Alameda|        CA|Black or African-...|  7364|\n",
      "|Alameda|        CA|  Hispanic or Latino|  8265|\n",
      "|Alameda|        CA|               Asian| 27984|\n",
      "| Albany|        NY|  Hispanic or Latino|  9368|\n",
      "+-------+----------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check subset of dataset that maybe causing dupliate rows\n",
    "us_demo.select(\"city\",\"state code\",\"Race\",\"count\").orderBy(\"city\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLEANING DATASET:\n",
    "1. 'Race' and 'Count' records are causing duplicate rows. We will separate them from US demographics data set and include 'City' and 'State Code'.\n",
    "2. 'Race' will be pivoted to column headers and saved to us_race_cnt dataset\n",
    "3. US_demo dataset will be cleaned of duplicate rows (shown above).\n",
    "4. Cleaned US_demo dataset will be joined back with us_race_cnt dataset to eventually have unique row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new columns from Race using Pivot and aggregating using count\n",
    "us_race_cnt=(us_demo.select(\"city\",\"state code\",\"Race\",\"count\")\n",
    "    .groupby(us_demo.City, \"state code\")\n",
    "    .pivot(\"Race\")\n",
    "    .agg(first(\"Count\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|        City|state code|American Indian and Alaska Native|Asian|Black or African-American|Hispanic or Latino| White|\n",
      "+------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|     Abilene|        TX|                             1813| 2929|                    14449|             33222| 95487|\n",
      "|       Akron|        OH|                             1845| 9033|                    66551|              3684|129192|\n",
      "|     Alafaya|        FL|                             null|10336|                     6577|             34897| 63666|\n",
      "|     Alameda|        CA|                             1329|27984|                     7364|              8265| 44232|\n",
      "|      Albany|        NY|                             1611| 8090|                    31303|              9368| 58368|\n",
      "|      Albany|        GA|                              445|  650|                    53440|              1783| 17160|\n",
      "| Albuquerque|        NM|                            32243|25140|                    26774|            271854|411847|\n",
      "|  Alexandria|        VA|                             1133|13315|                    37168|             25573|106215|\n",
      "|    Alhambra|        CA|                              687|44067|                     1905|             31386| 20811|\n",
      "|       Allen|        TX|                              227|15790|                    13140|             10615| 69840|\n",
      "|       Allen|        PA|                             1076| 2670|                    22304|             59176| 74187|\n",
      "|    Amarillo|        TX|                             4260| 8563|                    14050|             65392|174214|\n",
      "|        Ames|        IA|                             null| 8979|                     1103|              2024| 56157|\n",
      "|     Anaheim|        CA|                             2489|53270|                     9775|            201593|259820|\n",
      "|   Anchorage|        AK|                            36339|36825|                    23107|             27261|212696|\n",
      "|   Ann Arbor|        MI|                             1935|18797|                     9577|              5888| 90173|\n",
      "|     Antioch|        CA|                             3462|14333|                    23227|             35563| 51151|\n",
      "|Apple Valley|        CA|                             1446| 2281|                     9124|             25928| 60767|\n",
      "|    Appleton|        WI|                              835| 5561|                     3407|              5139| 64674|\n",
      "|Arden-Arcade|        CA|                             2587| 7355|                    13647|             15273| 69369|\n",
      "+------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking dataset\n",
    "us_race_cnt.orderBy(\"city\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns we don't need and drop duplicate rows\n",
    "uscols=[\"Number of Veterans\",\"Race\",\"Count\"]\n",
    "us_demo=us_demo.drop(*uscols).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(596, 596)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing row count between original and new dataset with dropped duplicate rows\n",
    "(us_demo.count(),us_race_cnt.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+-----------+----------+---------------+-----------------+----------------+------------+----------------------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|           City|State Code|      State|Median Age|Male Population|Female Population|Total Population|Foreign-born|Average Household Size|American Indian and Alaska Native|Asian|Black or African-American|Hispanic or Latino| White|\n",
      "+---------------+----------+-----------+----------+---------------+-----------------+----------------+------------+----------------------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|Highlands Ranch|        CO|   Colorado|      39.6|          49186|            53281|          102467|        8827|                  2.72|                             1480| 5650|                     1779|              8393| 94499|\n",
      "|           Kent|        WA| Washington|      33.4|          61825|            65137|          126962|       38175|                  3.06|                             3651|26168|                    20450|             21928| 67918|\n",
      "|        Madison|        WI|  Wisconsin|      30.7|         122596|           126360|          248956|       30090|                  2.23|                             2296|23937|                    20424|             19697|204302|\n",
      "|         Denver|        CO|   Colorado|      34.1|         341137|           341408|          682545|      113222|                  2.33|                            14008|32491|                    72288|            207847|546370|\n",
      "|         Caguas|        PR|Puerto Rico|      40.4|          34743|            42265|           77008|        null|                  null|                              624| null|                     null|             76349|  null|\n",
      "+---------------+----------+-----------+----------+---------------+-----------------+----------------+------------+----------------------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Joining us_demo and us_race-cnt on common city,state and code\n",
    "us_demo=us_demo.join(us_race_cnt, [\"city\",\"state code\"])\n",
    "us_demo.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change `state code` column name to `state_code` and other similar problems to avoid parquet complications\n",
    "us_demo=us_demo.select('City', col('State Code').alias('State_Code'), 'State', col('Median Age').alias('Median_age'),\n",
    "     col('Male Population').alias('Male_Population'), col('Female Population').alias('Female_Population'), \n",
    "        col('Total Population').alias('Total_Population'), 'Foreign-born', \n",
    "          col('Average Household Size').alias('Average_Household_Size'),\n",
    "             col('American Indian and Alaska Native').alias('American_Indian_and_Alaska_Native_Pop'), \n",
    "                 col('Asian').alias('Asian_Pop'), \n",
    "                    col('Black or African-American').alias('Black_or_AfricanAmerican_Pop'), \n",
    "                      col('Hispanic or Latino').alias('Hispanic_or_Latino_Pop'), \n",
    "                        col('White').alias('White_Pop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+----------+----------+---------------+-----------------+----------------+------------+----------------------+-------------------------------------+---------+----------------------------+----------------------+---------+\n",
      "|           City|State_Code|     State|Median_age|Male_Population|Female_Population|Total_Population|Foreign-born|Average_Household_Size|American_Indian_and_Alaska_Native_Pop|Asian_Pop|Black_or_AfricanAmerican_Pop|Hispanic_or_Latino_Pop|White_Pop|\n",
      "+---------------+----------+----------+----------+---------------+-----------------+----------------+------------+----------------------+-------------------------------------+---------+----------------------------+----------------------+---------+\n",
      "|Highlands Ranch|        CO|  Colorado|      39.6|          49186|            53281|          102467|        8827|                  2.72|                                 1480|     5650|                        1779|                  8393|    94499|\n",
      "|           Kent|        WA|Washington|      33.4|          61825|            65137|          126962|       38175|                  3.06|                                 3651|    26168|                       20450|                 21928|    67918|\n",
      "+---------------+----------+----------+----------+---------------+-----------------+----------------+------------+----------------------+-------------------------------------+---------+----------------------------+----------------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_demo.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the `state` column\n",
    "us_demo=us_demo.drop(\"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write (and overwrite) transformed `US_demo` dataset onto parquet file(In data folder)\n",
    "us_demo.write.mode('overwrite').parquet(\"./data/us_cities_demographics.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start ETL of i94 non-immigration dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read i94 non-immigration dataset\n",
    "i94_immigration=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cicid',\n",
       " 'i94yr',\n",
       " 'i94mon',\n",
       " 'i94cit',\n",
       " 'i94res',\n",
       " 'i94port',\n",
       " 'arrdate',\n",
       " 'i94mode',\n",
       " 'i94addr',\n",
       " 'depdate',\n",
       " 'i94bir',\n",
       " 'i94visa',\n",
       " 'count',\n",
       " 'dtadfile',\n",
       " 'visapost',\n",
       " 'occup',\n",
       " 'entdepa',\n",
       " 'entdepd',\n",
       " 'entdepu',\n",
       " 'matflag',\n",
       " 'biryear',\n",
       " 'dtaddto',\n",
       " 'gender',\n",
       " 'insnum',\n",
       " 'airline',\n",
       " 'admnum',\n",
       " 'fltno',\n",
       " 'visatype']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_immigration.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|\n",
      "|5748519.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20582.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     M|  null|     DL|9.495640653E10|00040|      B1|\n",
      "|5748520.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     F|  null|     DL|9.495645143E10|00040|      B1|\n",
      "|5748521.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  28.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1988.0|10292016|     M|  null|     DL|9.495638813E10|00040|      B1|\n",
      "|5748522.0|2016.0|   4.0| 245.0| 464.0|    HHW|20574.0|    1.0|     HI|20579.0|  57.0|    2.0|  1.0|20160430|     ACK| null|      G|      O|   null|      M| 1959.0|10292016|     M|  null|     NZ|9.498180283E10|00010|      B2|\n",
      "|5748523.0|2016.0|   4.0| 245.0| 464.0|    HHW|20574.0|    1.0|     HI|20586.0|  66.0|    2.0|  1.0|20160430|     ACK| null|      G|      O|   null|      M| 1950.0|10292016|     F|  null|     NZ|9.497968993E10|00010|      B2|\n",
      "|5748524.0|2016.0|   4.0| 245.0| 464.0|    HHW|20574.0|    1.0|     HI|20586.0|  41.0|    2.0|  1.0|20160430|     ACK| null|      G|      O|   null|      M| 1975.0|10292016|     F|  null|     NZ|9.497974673E10|00010|      B2|\n",
      "|5748525.0|2016.0|   4.0| 245.0| 464.0|    HOU|20574.0|    1.0|     FL|20581.0|  27.0|    2.0|  1.0|20160430|     ACK| null|      G|      O|   null|      M| 1989.0|10292016|     M|  null|     NZ|9.497324663E10|00028|      B2|\n",
      "|5748526.0|2016.0|   4.0| 245.0| 464.0|    LOS|20574.0|    1.0|     CA|20581.0|  26.0|    2.0|  1.0|20160430|     ACK| null|      G|      O|   null|      M| 1990.0|10292016|     F|  null|     NZ|9.501354793E10|00002|      B2|\n",
      "|5748527.0|2016.0|   4.0| 245.0| 504.0|    NEW|20574.0|    1.0|     MA|20576.0|  44.0|    2.0|  1.0|20160430|     GUZ| null|      G|      O|   null|      M| 1972.0|10292016|     M|  null|     UA|9.493828593E10|01215|      B2|\n",
      "|5748528.0|2016.0|   4.0| 245.0| 504.0|    LOS|20574.0|    1.0|   null|20575.0|  39.0|    2.0|  1.0|20160430|     GUZ| null|      G|      O|   null|      M| 1977.0|10292016|     M|  null|     CM|9.501810463E10|00472|      B2|\n",
      "|5748529.0|2016.0|   4.0| 245.0| 504.0|    WAS|20574.0|    1.0|     VA|20596.0|  38.0|    2.0|  1.0|20160430|     PNM| null|      G|      O|   null|      M| 1978.0|10292016|     M|  null|     CM|9.492489983E10|00488|      B2|\n",
      "|5748530.0|2016.0|   4.0| 245.0| 504.0|    LOS|20574.0|    1.0|     CA|20577.0|  56.0|    2.0|  1.0|20160430|     PNM| null|      G|      O|   null|      M| 1960.0|10292016|     F|  null|     CM|9.492648103E10|00302|      B2|\n",
      "|5748531.0|2016.0|   4.0| 245.0| 504.0|    LOS|20574.0|    1.0|     CA|20577.0|  38.0|    2.0|  1.0|20160430|     PNM| null|      G|      O|   null|      M| 1978.0|10282016|     M|  null|     CM|9.492629303E10|00302|      B2|\n",
      "|5748532.0|2016.0|   4.0| 245.0| 504.0|    MIA|20574.0|    1.0|     FL|20581.0|  53.0|    2.0|  1.0|20160430|     PNM| null|      G|      O|   null|      M| 1963.0|10292016|     F|  null|     CM|9.500640513E10|00430|      B2|\n",
      "|5748534.0|2016.0|   4.0| 245.0| 528.0|    SFR|20574.0|    1.0|     CA|   null|  84.0|    2.0|  1.0|20160430|     HNK| null|      G|   null|   null|   null| 1932.0|10282016|     F|  null|     CX|9.492476223E10|00872|      B2|\n",
      "|5748876.0|2016.0|   4.0| 245.0| 582.0|    HOU|20574.0|    1.0|     TX|20583.0|  43.0|    1.0|  1.0|20160430|     GUZ| null|      G|      O|   null|      M| 1973.0|10292016|     M|  null|     UA|9.499463063E10|05574|      B1|\n",
      "|5748877.0|2016.0|   4.0| 245.0| 582.0|    HOU|20574.0|    1.0|     TX|20583.0|  30.0|    1.0|  1.0|20160430|     GUZ| null|      G|      O|   null|      M| 1986.0|10292016|     F|  null|     UA|9.499447663E10|05574|      B1|\n",
      "|5748881.0|2016.0|   4.0| 245.0| 582.0|    LOS|20574.0|    1.0|     CA|20575.0|  34.0|    2.0|  1.0|20160430|     SHG| null|      G|      O|   null|      M| 1982.0|10292016|     M|  null|     AM|9.496770903E10|00646|      B2|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_immigration.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we are taking into consideration the following columns as it makes sense and omitting the remaining columns.This will be basis of our facts tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert columns reads as string/doublr to integer\n",
    "i94_immigration=i94_immigration.select(col(\"i94res\").cast(IntegerType()),col(\"i94port\"),\\\n",
    "                           col(\"cicid\").cast(IntegerType()),\n",
    "                           col(\"arrdate\").cast(IntegerType()), \\\n",
    "                           col(\"i94mode\").cast(IntegerType()),col(\"depdate\").cast(IntegerType()),\n",
    "                           col(\"i94bir\").cast(IntegerType()),col(\"i94visa\").cast(IntegerType()), \n",
    "                           col(\"count\").cast(IntegerType()), \\\n",
    "                              \"gender\",\"fltno\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3096313, 3096313)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for duplicate rows on each dataset by comparing original total rows with .dropDuplicates()\n",
    "i94_immigration.count(), i94_immigration.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----+---+----------+----------+----+----------+----------+---------------+-----------------+----------------+------------+----------------------+-------------------------------------+---------+----------------------------+----------------------+---------+------------+\n",
      "|i94res|i94port|  cicid|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|fltno| id| port_city|port_state|City|State_Code|Median_age|Male_Population|Female_Population|Total_Population|Foreign-born|Average_Household_Size|American_Indian_and_Alaska_Native_Pop|Asian_Pop|Black_or_AfricanAmerican_Pop|Hispanic_or_Latino_Pop|White_Pop|arrival_date|\n",
      "+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----+---+----------+----------+----+----------+----------+---------------+-----------------+----------------+------------+----------------------+-------------------------------------+---------+----------------------------+----------------------+---------+------------+\n",
      "|   582|    GSP|4792689|  20569|      1|   null|    51|      1|    1|     M|XAPTR|GSP|GREENVILLE|        SC|null|      null|      null|           null|             null|            null|        null|                  null|                                 null|     null|                        null|                  null|     null|  2016-04-25|\n",
      "|   582|    GSP|4792690|  20569|      1|  20612|    39|      1|    1|     M|XAPTR|GSP|GREENVILLE|        SC|null|      null|      null|           null|             null|            null|        null|                  null|                                 null|     null|                        null|                  null|     null|  2016-04-25|\n",
      "|   582|    GSP|4792691|  20569|      1|  20573|    59|      1|    1|     M|XAPTR|GSP|GREENVILLE|        SC|null|      null|      null|           null|             null|            null|        null|                  null|                                 null|     null|                        null|                  null|     null|  2016-04-25|\n",
      "+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----+---+----------+----------+----+----------+----------+---------------+-----------------+----------------+------------+----------------------+-------------------------------------+---------+----------------------------+----------------------+---------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_immigration.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I have transformed I94_SAS-Labels_Description into I-94ADDR.csv,I94CIT_I94RES.csv,I94MODE.csv,I94Visa.csv and finally saving them into respective parquet files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL I94Mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "| ID|        Mode|\n",
      "+---+------------+\n",
      "|  1|         Air|\n",
      "|  2|         Sea|\n",
      "|  3|        Land|\n",
      "|  9|Not reported|\n",
      "+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create i94mode list\n",
    "i94mode=spark.read.csv('./I94MODE.csv',header=True)\n",
    "i94mode.show()\n",
    "# Create i94mode parquet file\n",
    "i94mode.write.mode(\"overwrite\").parquet('./data/i94mode.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL I94Port "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Port_city</th>\n",
       "      <th>Port_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                 Port_city Port_state\n",
       "0  ALC                     ALCAN         AK\n",
       "1  ANC                 ANCHORAGE         AK\n",
       "2  BAR  BAKER AAF - BAKER ISLAND         AK\n",
       "3  DAC             DALTONS CACHE         AK\n",
       "4  PIZ    DEW STATION PT LAY DEW         AK"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read i94port CSV file\n",
    "i94port= pd.read_csv('./I94PORT.csv')\n",
    "new=i94port['Port'].str.split(\",\",expand=True)\n",
    "i94port['Port_city']=new[0]\n",
    "i94port['Port_state']=new[1]\n",
    "i94port.drop(columns=['Port'],inplace=True)\n",
    "i94port.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now convert pd dataframe to spark dataframe\n",
    "# Create a schema for the dataframe\n",
    "i94port_schema = StructType([\n",
    "    StructField('id', StringType(), True),\n",
    "    StructField('port_city', StringType(), True),\n",
    "    StructField('port_state', StringType(), True)\n",
    "])\n",
    "i94port=spark.createDataFrame(i94port, i94port_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parquet file\n",
    "i94port.write.mode('overwrite').parquet('./data/i94port.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL I94Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+\n",
      "|Code|        country|\n",
      "+----+---------------+\n",
      "| 582|         MEXICO|\n",
      "| 236|    AFGHANISTAN|\n",
      "| 101|        ALBANIA|\n",
      "| 316|        ALGERIA|\n",
      "| 102|        ANDORRA|\n",
      "| 324|         ANGOLA|\n",
      "| 529|       ANGUILLA|\n",
      "| 518|ANTIGUA-BARBUDA|\n",
      "| 687|      ARGENTINA|\n",
      "| 151|        ARMENIA|\n",
      "| 532|          ARUBA|\n",
      "| 438|      AUSTRALIA|\n",
      "| 103|        AUSTRIA|\n",
      "| 152|     AZERBAIJAN|\n",
      "| 512|        BAHAMAS|\n",
      "| 298|        BAHRAIN|\n",
      "| 274|     BANGLADESH|\n",
      "| 513|       BARBADOS|\n",
      "| 104|        BELGIUM|\n",
      "| 581|         BELIZE|\n",
      "+----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read I94CIT_I94RES.csv \n",
    "i94res=spark.read.csv('./I94CIT_I94RES.csv',header=True)\n",
    "i94res=i94res.withColumnRenamed('I94CTRY','country')\n",
    "i94res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parquet file\n",
    "i94res.write.mode('overwrite').parquet('./data/i94res.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL I94Visa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID', 'Type']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read I94 Visa\n",
    "i94visa=spark.read.csv('./I94VISA.csv',header=True)\n",
    "i94visa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parquet file\n",
    "i94visa.write.mode('overwrite').parquet('./data/i94visa.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining I94_immigration and I94Port(left join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add i94port city and state columns to i94 dataframe\n",
    "i94_immigration=i94_immigration.join(i94port, i94_immigration.i94port==i94port.id, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----+---+---------+----------+\n",
      "|i94res|i94port|  cicid|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|fltno| id|port_city|port_state|\n",
      "+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----+---+---------+----------+\n",
      "|   297|    BGM|5761355|  20574|      1|   null|    63|      1|    1|     F|00812|BGM|   BANGOR|        ME|\n",
      "|   297|    BGM|5761356|  20574|      1|  20674|    43|      1|    1|     M|00812|BGM|   BANGOR|        ME|\n",
      "|   297|    BGM|5761357|  20574|      1|  20685|    48|      1|    1|     M|00812|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM| 460085|  20547|      1|  20550|    34|      2|    1|     M|EDC10|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM| 473180|  20547|      1|  20687|    69|      1|    1|     M|EDC92|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM| 473264|  20547|      1|   null|    64|      1|    1|     M|EDC92|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM| 473265|  20547|      1|   null|    63|      2|    1|     F|EDC92|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM| 473367|  20547|      1|  20550|    53|      2|    1|     M|MCELT|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM| 473368|  20547|      1|  20551|    36|      2|    1|     M|MCELT|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM| 473369|  20547|      1|   null|    36|      1|    1|     F|EDC92|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM| 473370|  20547|      1|  20554|    49|      1|    1|     M|EDC92|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM| 473371|  20547|      1|  20557|    26|      1|    1|     M|EDC92|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM| 474644|  20547|      1|  20678|    62|      2|    1|     M|07542|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM| 474645|  20547|      1|  20678|    40|      2|    1|     F|07542|BGM|   BANGOR|        ME|\n",
      "|   373|    BGM| 516509|  20547|      1|  20549|    55|      1|    1|     M|MBAEP|BGM|   BANGOR|        ME|\n",
      "|   158|    BGM| 625524|  20547|      1|  20550|    49|      2|    1|     F|EDC10|BGM|   BANGOR|        ME|\n",
      "|   158|    BGM| 625525|  20547|      1|  20550|    15|      2|    1|     F|EDC10|BGM|   BANGOR|        ME|\n",
      "|   158|    BGM| 625526|  20547|      1|  20550|    13|      2|    1|     M|EDC10|BGM|   BANGOR|        ME|\n",
      "|   332|    BGM|1983363|  20555|      1|  20560|    71|      1|    1|     M|CNTNM|BGM|   BANGOR|        ME|\n",
      "|   332|    BGM|2049259|  20555|      1|  20560|    40|      1|    1|     M|CNTNM|BGM|   BANGOR|        ME|\n",
      "+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----+---+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_immigration.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City',\n",
       " 'State_Code',\n",
       " 'Median_age',\n",
       " 'Male_Population',\n",
       " 'Female_Population',\n",
       " 'Total_Population',\n",
       " 'Foreign-born',\n",
       " 'Average_Household_Size',\n",
       " 'American_Indian_and_Alaska_Native_Pop',\n",
       " 'Asian_Pop',\n",
       " 'Black_or_AfricanAmerican_Pop',\n",
       " 'Hispanic_or_Latino_Pop',\n",
       " 'White_Pop']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_demo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join US with i94_spark to get fact table `i94non_immigrant_port_entry`\n",
    "# NOTE: We use left join againt city records which may cause null values because\n",
    "# we may not currently have demographic stats on all U.S. ports of entry\n",
    "i94_immigration=i94_immigration.join(us_demo, (upper(i94_immigration.port_city)==upper(us_demo.City)) & \\\n",
    "                                           (upper(i94_immigration.port_state)==upper(us_demo.State_Code)), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_immigration.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----+---+----------+----------+----+----------+----------+---------------+-----------------+----------------+------------+----------------------+-------------------------------------+---------+----------------------------+----------------------+---------+\n",
      "|i94res|i94port|  cicid|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|fltno| id| port_city|port_state|City|State_Code|Median_age|Male_Population|Female_Population|Total_Population|Foreign-born|Average_Household_Size|American_Indian_and_Alaska_Native_Pop|Asian_Pop|Black_or_AfricanAmerican_Pop|Hispanic_or_Latino_Pop|White_Pop|\n",
      "+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----+---+----------+----------+----+----------+----------+---------------+-----------------+----------------+------------+----------------------+-------------------------------------+---------+----------------------------+----------------------+---------+\n",
      "|   582|    GSP|4792689|  20569|      1|   null|    51|      1|    1|     M|XAPTR|GSP|GREENVILLE|        SC|null|      null|      null|           null|             null|            null|        null|                  null|                                 null|     null|                        null|                  null|     null|\n",
      "|   582|    GSP|4792690|  20569|      1|  20612|    39|      1|    1|     M|XAPTR|GSP|GREENVILLE|        SC|null|      null|      null|           null|             null|            null|        null|                  null|                                 null|     null|                        null|                  null|     null|\n",
      "|   582|    GSP|4792691|  20569|      1|  20573|    59|      1|    1|     M|XAPTR|GSP|GREENVILLE|        SC|null|      null|      null|           null|             null|            null|        null|                  null|                                 null|     null|                        null|                  null|     null|\n",
      "|   582|    GSP|4804743|  20569|      1|  20570|    55|      1|    1|     M|XAPTR|GSP|GREENVILLE|        SC|null|      null|      null|           null|             null|            null|        null|                  null|                                 null|     null|                        null|                  null|     null|\n",
      "|   582|    GSP|4804744|  20569|      1|  20571|    51|      1|    1|     M|XAPTR|GSP|GREENVILLE|        SC|null|      null|      null|           null|             null|            null|        null|                  null|                                 null|     null|                        null|                  null|     null|\n",
      "+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----+---+----------+----------+----+----------+----------+---------------+-----------------+----------------+------------+----------------------+-------------------------------------+---------+----------------------------+----------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_immigration.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i94res',\n",
       " 'i94port',\n",
       " 'cicid',\n",
       " 'arrdate',\n",
       " 'i94mode',\n",
       " 'depdate',\n",
       " 'i94bir',\n",
       " 'i94visa',\n",
       " 'count',\n",
       " 'gender',\n",
       " 'fltno',\n",
       " 'id',\n",
       " 'port_city',\n",
       " 'port_state',\n",
       " 'City',\n",
       " 'State_Code',\n",
       " 'Median_age',\n",
       " 'Male_Population',\n",
       " 'Female_Population',\n",
       " 'Total_Population',\n",
       " 'Foreign-born',\n",
       " 'Average_Household_Size',\n",
       " 'American_Indian_and_Alaska_Native_Pop',\n",
       " 'Asian_Pop',\n",
       " 'Black_or_AfricanAmerican_Pop',\n",
       " 'Hispanic_or_Latino_Pop',\n",
       " 'White_Pop']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_immigration.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SAS arrival date to datetime format\n",
    "get_date = udf(lambda x: (dt.datetime(1960, 1, 1).date() + dt.timedelta(x)).isoformat() if x else None)\n",
    "i94_immigration= i94_immigration.withColumn(\"arrival_date\", get_date(i94_immigration.arrdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94_immigration=i94_immigration.withColumnRenamed('i94res','res_id')\\\n",
    "                               .withColumnRenamed('i94port','port_id')\\\n",
    "                               .withColumnRenamed('i94mode','mode_id')\\\n",
    "                               .withColumnRenamed('i94visa','visa_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----+---+----------+----------+----+----------+----------+---------------+-----------------+----------------+------------+----------------------+-------------------------------------+---------+----------------------------+----------------------+---------+------------+\n",
      "|res_id|port_id|  cicid|arrdate|mode_id|depdate|i94bir|visa_id|count|gender|fltno| id| port_city|port_state|City|State_Code|Median_age|Male_Population|Female_Population|Total_Population|Foreign-born|Average_Household_Size|American_Indian_and_Alaska_Native_Pop|Asian_Pop|Black_or_AfricanAmerican_Pop|Hispanic_or_Latino_Pop|White_Pop|arrival_date|\n",
      "+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----+---+----------+----------+----+----------+----------+---------------+-----------------+----------------+------------+----------------------+-------------------------------------+---------+----------------------------+----------------------+---------+------------+\n",
      "|   582|    GSP|4792689|  20569|      1|   null|    51|      1|    1|     M|XAPTR|GSP|GREENVILLE|        SC|null|      null|      null|           null|             null|            null|        null|                  null|                                 null|     null|                        null|                  null|     null|  2016-04-25|\n",
      "|   582|    GSP|4792690|  20569|      1|  20612|    39|      1|    1|     M|XAPTR|GSP|GREENVILLE|        SC|null|      null|      null|           null|             null|            null|        null|                  null|                                 null|     null|                        null|                  null|     null|  2016-04-25|\n",
      "+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----+---+----------+----------+----+----------+----------+---------------+-----------------+----------------+------------+----------------------+-------------------------------------+---------+----------------------------+----------------------+---------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_immigration.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94_immigration.drop('arrdate').write.mode(\"overwrite\").parquet('./data/i94_immigration.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94date=i94_immigration.select(\n",
    "                                col('arrival_date'),\n",
    "                                date_format('arrival_date','M').alias('arrival_month'),\n",
    "                                date_format('arrival_date','E').alias('arrival_dayofweek'), \n",
    "                                date_format('arrival_date', 'y').alias('arrival_year'), \n",
    "                                date_format('arrival_date', 'd').alias('arrival_day'),\n",
    "                                date_format('arrival_date','w').alias('arrival_weekofyear')).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-----------------+------------+-----------+------------------+\n",
      "|arrival_date|arrival_month|arrival_dayofweek|arrival_year|arrival_day|arrival_weekofyear|\n",
      "+------------+-------------+-----------------+------------+-----------+------------------+\n",
      "|  2016-04-05|            4|              Tue|        2016|          5|                15|\n",
      "|  2016-04-29|            4|              Fri|        2016|         29|                18|\n",
      "|  2016-04-20|            4|              Wed|        2016|         20|                17|\n",
      "|  2016-04-17|            4|              Sun|        2016|         17|                17|\n",
      "|  2016-04-12|            4|              Tue|        2016|         12|                16|\n",
      "+------------+-------------+-----------------+------------+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94date.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94date.write.mode(\"overwrite\").partitionBy(\"arrival_year\", \"arrival_month\").parquet('./data/i94date.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "#### Map out the conceptual data model and explain why you chose that model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are selecting star schema with i94_immigrations as facts table and i94date,i94mode,i94port,i94res,i94visa and us_cities demographics as dimensions tables.As we have stored variuos dimensions and facts tables in parquet files under data in workspace and in S3 buckets (AWS)  we can easily implement them in AWS Redshift.We create the schema by running the SQL script found in create_tables.sql. From there, our model is ready to be explored by the customers whether through open query editor in Redshift itself or using a dashboard tool such as Tableau or Power BI..We are storing data in its lowest granularity as to allow complex queries with better performance and flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "#### To accomplish all task related to preprocessing of datasets I have used etl.py and etl1.py.There you will find different functions to load,select,clean,transform and store results in datasets in a convinent way.The open-source framework Apache Spark was the main tool in this journey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follwing are the steps to pipeline the data into model\n",
    "1. Create the dimensions (i94port, i94visa, i94res, i94mode) from i94_SAS_Labels_Descriptions.SAS file. *NOTE: Once they're created it does not have to be included in future Data Pipeline schedules because these are essentially master records which do not frequently get added or changed on the dimension tables.\n",
    "2.  US Cities Demo dataset file to form us_demo dataframe\n",
    "3. Create 'us_race_cnt' from us_demo\n",
    "4. Write (and overwrite) transformed US_cities_demographics onto parquet file\n",
    "5. Read i94port dimension parquet file so we can use it to join with i94_immigration. This will add i94port city and state columns to i94_immigration\n",
    "6. join i94_immigration and US_demo to form fact i94_immigration \n",
    "7. time dimension from i94_immigration and save to parquet file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data pipelines is built inside etl.py and etl1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed reading data file.\n",
      "Transformation went perfect.\n",
      "Passed reading data file.\n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "if us_demo.count() > 0:\n",
    "    print('Passed reading data file.')\n",
    "else:\n",
    "    print('Seems to be nothing in file!')\n",
    "\n",
    "if us_demo.count() == us_race_cnt.count():\n",
    "    print('Transformation went perfect.')\n",
    "else:\n",
    "    print('Inconsistant data between both dataframes!')\n",
    "\n",
    "if i94_immigration.count() > 0:\n",
    "    print('Passed reading data file.')\n",
    "else:\n",
    "    print('Seems to be nothing in file!')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "'''\n",
    "\n",
    "## i94date\n",
    "#### arrival_date Date PK  :   Non-immigrant arrival date in the USA \n",
    "#### arrival_month int    :   Non-immigrant arrival month\n",
    "#### arrival_day int      :   Non-immigrant arrival day\n",
    "#### arrival_year int     :   Non-immigrant arrival year\n",
    "#### arrival_week int     :   Non immigrant week of year\n",
    "\n",
    "##   i94port\n",
    "#### id string PK         : 3 character code of destination USA city\n",
    "#### port_city varchar    : city name\n",
    "#### port_state varchar   : state name\n",
    "\n",
    "##   i94visa\n",
    "#### id int PK            : visa code number\n",
    "#### type string          : Type of visa\n",
    "\n",
    "##   i94res\n",
    "#### code int PK          : 3 digit code of nationality \n",
    "#### country varchar      : country of Immigrant\n",
    "\n",
    "##   i94mode\n",
    "#### id int PK            : 1 digit code (plane, boat, etc) of travel \n",
    "#### transport varchar    : Mode of transport according to code\n",
    "\n",
    "##   i94_immigrant\n",
    "#### cicid int PK         : ID that uniquely identify one record in the dataset\n",
    "#### arrival_date date FK : arrival date in the USA\n",
    "#### depdate int          : Departure Date from the USA\n",
    "#### port_id string FK    : i94port.id 3 character code of destination USA city from i94 non-immigration data\n",
    "#### visa_id int FK       : i94visa.id reason for immigration from i94 non-immigration data\n",
    "#### res_id int FK        : i94res.id 3 digit code of nationality from i94 non-immigration data\n",
    "#### mode_id int FK       : i94mode.id 1 digit mode (plane, boat, etc) of travel code from i94 non-immigration data\n",
    "#### age int              : Age of non-immigrant in years from i94 non-immigration data\n",
    "#### gender string        : Non-immigrant sex from i94 non-immigration data\n",
    "#### cnt_of_one int       : count of one per row used for statistical metrics from i94 non-immigration data\n",
    "#### median_age float     : Median age of population in city and state from US cities demographics data\n",
    "#### male_pop int         : Male population of city and state from US cities demographics data\n",
    "#### female_pop int       : Female population of city and state from US cities demographics data\n",
    "#### total_pop int          : Total population of city and state from US cities demographics data\n",
    "#### foreign_born_pop int : Foreign born population of city and state from US cities demographics data\n",
    "#### avg_household_size float :Average household size of city and state from US cities demographics data\n",
    "#### american_indian_alaskan_native_pop int : Aerican Indian population of city and state from US cities demographics data\n",
    "#### asian_pop int        : Asian population of city and state from US cities demographics data\n",
    "#### black_african_american_pop int : Black population of city and state from US cities demographics data\n",
    "#### hispanic_pop int     : Hispanic population of city and state from US cities demographics data\n",
    "#### white_pop int        : White population of city and state from US cities demographics data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "The whole solution implemented here is mounted on top of cloud computing technology, AWS in particular. Because the cloud computing provides a low-cost, scalable, and highly reliable infrastructure platform in the cloud this is a natural choice for every new solution like we did here. Every service we use (S3, EMR, Redshift) has reasonable cost and is ‘pay as you go’ pricing. So we can start small and scale as our solution grows. No up-front costs involved.\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "1.  I94_immigrant and date dimension need to be updated monthly\n",
    "2.  The US Cities Demographics data is updated every ten years according to https://www.usa.gov/statistics. So, the new US Cities Demographics data set maybe coming after year 2020. And may need updating after one year or two years as of 2019.\n",
    "\n",
    "\n",
    "* The data was increased by 100x.\n",
    "Deploy this Spark solution on a cluster using AWS (EMR cluster) and use S3 for data and parquet file storage. AWS will easily scale when data increases by 100x\n",
    "\n",
    "* The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "\n",
    "* The database needed to be accessed by 100+ people.\n",
    "There should be no problem with 100 or so people accessing this data. However, the date-partitioned nature of the solution proposed above would also help in this case. If access by multiple users continues to be a problem you can mitigate that by having the data replicate to different nodes used by different users. If your users are located around the world, a replication node near each group of people would be best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
